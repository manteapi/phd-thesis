=====================================================================================
                                    Introduction
=====================================================================================

Slide 1
========

Bonjour à tous.
Je suis Pierre-Luc Manteaux et je vais vous présenter les travaux réalisés pendant ma thèse,
intitulée "Simulation et contrôle de phénomènes physiques", qui a été supervisé par François
Faure et Marie-Paule Cani, au sein de l'équipe IMAGINE du laboratoire Jean Kuntzmann.

Slide 2
========
Cette thèse s'inscrit dans le domaine de l'informatique graphique, 
qui étudie comment créer et intéragir avec des scènes virtuelles.
Une des applications phare de l'IG, qui l'a fait connaître au grand public, c'est l'animation.
Au milieu des années 80, les dessins animés, qui étaient traditionnellement réalisé à la main,
vont être créér à l'aide d'ordinateurs.
Ça permet d'économiser un temps considérable sur des tâches répétitives.
Sans brider l'imagination et la capacité à transmettre des émotions.
Très rapidement, de nouveaux outils émergent, permettent de créer des animations toujours plus spec.(complexité, réalisme).
Un de ces outils, qui va devenir indispensable, c'est la simulation physique.
Qui fait partie des domaines dans lesquels s'inscrit ma thèse également.
Elle va permettre de créer automatiquement des animations complexes et réalistes.
Des animations qui auraient été très difficile, voire quasi-impossible à obtenir par le dessin.

Slide 3
========
Au delà du cinéma, on retrouve l'IG et la SP dans d'autres applications pour le divertissement (JV).
Mais aussi dans d'autres domaines, comme l'enseigment (simulateur), et la fabrication (design).
La capacité à simuler/visualiser/intéragir avec des comportements réalistes est importante. 
Pour rendre les EV plus immersifs ou accélerer les processus de design.
Pour que ces applications remplissent leurs objectifs, 
il y a plusieurs défis auxquels la simulation physique doit faire face. 
Je vais en introduire trois qui font échos aux travaux de ma thèse.

Slide 4
========
Un des premiers défis qu'on rencontre, c'est celui de la complexité calculatoire.
Une simulation peut nécessiter des ressources informatiques importantes (mémoire, unité de calcul).
Pour vous donner une idée, avec un simulateur récent pour l'animation de liquide.
Une scène à haute résolution comme celle-ci va nécessiter 30h de calcul pour 20s de simulation.
Ça restreint l'utilisation de ce solver, tel quel, à des applications non interactives.
La résolution des scènes est limitée au temps que l'on est prêt à attendre.
Il y a un besoin constant de nouvelles techniques qui permettent de
simuler des phénomènes à haute résolution avec des ressources informatiques qui sont limitées.

Slide 5
========
Le second défi, lui, est relatif à la description des phénomènes que l'on cherche à simuler.
Aujourd'hui on est capable de représenter de manière efficace de nombreux phénomènes.
(rigide,déformable,fluide,liquide).
On les retrouve fréquemment dans des environnements intéractifs grand publics:jeux vidéos, logiciel.
En revanche, ce que l'on trouve moins, ce sont des phénomènes qui mettent en jeu des changements de formes et d'état important comme la découpe/fracture d'objets déformables. 
Pour retrouver ces phénomènes dans des contextes intéractifs, où ils sont très attendu.
On a besoin de nouveaux modèles qui puissent les décrire efficacement.
Ça rejoint le premier défis mais avec un accent sur le phénomène lui même et pas sa résolution.

Slide 6
========
Le troisième défi concerne le design et le contrôle de simulation.
Dans les logiciels existants, ça reste des tâches difficiles, qui demandent beaucoup de temps.
Principalement pour trois raisons:
-La première concerne l'interface très peu intuitive au premier abord.
-La second concerne le contrôle qui est indirect.
Même en ayant une idée précise de ce que l'on souhaite obtenir, ça va rester difficile de définir les paramètres sur lesquels on à la main pour obtenir le résultat voulu.
-La troisième, c'est le temps de calcul. Qui va limiter l'exploration des paramètres à la patience.
Alors ça n'empêche pas ces logiciels de produire de superbes résultats.
Mais ils restent peu accessible aux grands publics, même si certains sont gratuits.
Il y un besoin d'outils simple, direct, intuitifs pour le contrôle de simulations.

Slide 7
========
Ok, ce sont les trois défis autour desquelles s'articulent les contributions de cette thèse.
Tout d'abord, on a étudié les modèles adaptatifs existants.
On a étendu un modèle issu du domaine de la dynamique moléculaire à l'informatique graphique, 
pour la simulation de liquide/vêtement.
Ensuite, on s'est intéressé à la simulation de découpe. On propose une technique qui permet de simuler de manière intéractive des découpes très détaillées d'objets fins.
Enfin, sur le contrôle de simulation, on propose une nouvelle approche qui consiste à éditer des animations de liquide existantes à l'aide d'outils inspirés de la sculpture virtuelle.

=====================================================================================
                                        ARPS
=====================================================================================

Slide 8
========
Je vais commencer par introduire les modèles physiques adaptatifs pour l'informatique graphique.

Slide 9
=======
Comme je le disais précédemment, une simulation physique peut coûter très cher en temps de calcul.
Pour schématiser, plus le phénomène est complexe et plus on cherche à avoir un résultat réaliste.
Plus on va devoir utiliser un échantillonnage dense à la fois spatial et temporel pour représenter
fidèlement les détails que l'on cherche à capturer. 
Ça peut être les plis d'un vêtements, rides d'un personnage, vagues/eclaboussures pour l'eau.
Dans tout ces cas, le nombre d'échantillons va résulter en un coût important, voire prohibitif.
Les techniques adaptatives proposent une approche générale à ce problème.
Qui consiste à modifier les différents composants de la simulation, dynamiquement,
pour obtenir le meilleur compromis entre précision, performance et stabilité.

Slide 10
========
On distingue deux grandes familles de méthodes adaptatives.
Selon qu'elles s'intéressent à l'aspect spatiale ou temporel de la simulation.
Dans ces deux familles, on retrouve une stratégie similaire qui a donne lieu à beaucoup de rech.
Et qui consiste à adapter dynamiquement la densité de l'échantillonnage selon certains critères.
Pour l'aspect spatial:
Ça va consister à raffiner la discrétisation dans les régions visuellement intéressantes, 
comme la surface de l'eau et les régions de grandes déformations.
Et à la simplifier dans celles qui le sont moins, pour pouvoir gagner du temps.
Pour l'aspect temporel:
Ça va consister à adapter le pas de temps aux événements.
Pour des événements rapides (chocs), avoir un dt suffisamment petit pour la stabilité.
Et à l'inverse, dès que la simulation le permet, avoir un dt + grand possible.

Slide 11
========
L'adaptativité ne se résume pas seulement à ces deux familles et à cette stratégie.
Il y en a bien d'autre et on peut les regrouper dans différentes catégories.
Je ne vais pas les détailler, juste quelques limitations communes aux travaux précédents.
Dans l'idéal, ces méthodes seraient des boîte noire que l'on pourrait ajouter à un modèle existant,
dans un n'importe quel simulateur, pour le rendre adaptatif et le plier à nos besoins.
En pratique c'est rarement le cas. 
C'est souvent des techniques complexes à implémenter et assez intrusive. 
i.e que pour les intégrer efficacement dans un simulateur existant, 
il faudra peut être remettre en cause l'architecture du simulateur.
Du coup la réutilisation d'implémentation est difficile.
Et enfin on peut rencontrer des incompatibilités entre une méthode adaptative 
et avec d'autres techniques d'accélération (GPU).
Même si des résultats très impressionnants peuvent être obtenus, 
Ces limitations freinent leur utilisation dans des logiciels grand publics.

Slide 12
========
Le modèle adaptatif que je vais présenter répond en partie à ces limites.
Il appartient à la famille des méthodes de freezing (rouge).

Slide 13
========
Elles ont pour objectif de gagner du temps dans des situations quasi-statiques. (no move).
En restraignant la simulation aux zones actives, générallement visuellement intéressantes.
On trouve essentiellement des travaux concernant les R et les RA. Et 1 travail pour liquide.
Pour les R, le F est utilisé pour accélérer le traitement des collisions dans des scé. d'empilement.
en ne traitant pas les groupes d'objets immobiles et en contact qui sont alors dit inactif.
Pour les RA, les joints sont activés/désactivé en fonction de critère visuel, 
comme la distance à la caméra pour simplifier les objets.
Et enfin le travail de Goswami et al. sur les liquides particulaires.
Qui consiste à approximer les particules lentes par des particules immobiles 
et à ne simuler que les particules actives pour réduire compl.
Ce travail est assez proche du notre puisqu'il traite du cas des liquide,
mais malheureusement il ne respecte pas le principe d'action/réaction 
et la question de quand/comment réactiver les particules de manière cohérente n'est pas addréssée.

Slide 14
========
En 2012, dans le domaine de la dynamique moléculaire, Artemova et Redon prop. un modèle de freezing.
Qui intègre et résoud de manière simple cette question, et qui s'appelle ARPS.
L'idée de base est similaire à celle de Goswami et al.
Les particules lentes sont considérées immobile, inactives.
Du coup les forces inter-particules sont constantes et n'ont plus à être calculées.
La différence est dans l'intégration du mouvement des particules.
Toute les particules, actives ou inactives sont intégrées.
La quantité de mouvement associée aux forces constantes continuent d'être accumulée.
Jusqu'à un certain seuil où la particule va redevenir active.
Artemova et Redon ont proposé une légère modification des équations du mouvement qui permet à la
particule ré-activée de suivre un mouvement physiquement cohérent et de ne pas partir comme un boulet de canon.
La méthode a été validée sur différents exemples comme en bas à droite.
Elle permet d'obtenir des accélérations intéressantes, 
de préserver les caractéristiques de la simulation.
Je vais prendre l'exemple d'un oscillateur pour mieux illustrer son fonctionnement.

Slide 15
=========
Sur la gauche un oscillateur harmonique, deux particules reliés par un ressort, une particule fixe.
Sur la droite le protrait de phase de la simulation qui décrit l'évolution de la quantité de mouvement en fonction de la position de la particule. 
Pendant une simulation classique, la force inter-particule est calculée à chaque pas de temps,
Maintenant, le même système mais simulé avec l'ARPS.
Le portrait de phase est légèrement différent.
Il est divisée en trois régions qui décrivent les différentes dynamiques(restr., trans., classique.)
A ces dynamiques, correspond l'état de la particule, qui peut être inactive, trans., active.
Pendant la dynamique restrainte, la particule est immobile aucune force n'est calculée, 
mais la particule accumule de la quantité de mouvement jusqu'à un certain seuil. 
Alors la particule devient transitive.
L'objectif de cette phase est de faire le lien entre la dynamique restreinte et classique.
Ensuite la particule redevient active et suit une dynamique classique.
Et donc, en utilisant des seuils adaptés pour la zone de transition, on peut avoir une simulation adaptative qui reste proche de la simulation de référence.

Slide 16
========
Nos contributions, ici, se limitent à l'extension de cette méthode à des applications pour l'IG.
Tout d'abord, on propose d'appliquer l'ARPS à la simulation de liquide.
Ensuite, dans le cadre de la simulation de vêtement, on propose un intégrateur implicite, dérivé de l'ARPS.

Slide 17
=========
Pour la simulation de liquide, on a choisi de combiner l'ARPS avec le modèle SPH de Becker et al.
Ce modèle permet de simuler un liquide à l'aide de particules qui interpolent les différentes 
quantités qui décrivent le liquide (pression, densité, vitesse, ...).
Il est assez gourmand parce que pour chaque particule on fait une recherche de voisinage.
En utilisant l'intégrateur proposé par Artemova et Redon, on peut écrire un algorithme incrémentale
qui restreint les calculs aux particules inactives: forces/scalaires qui interviennent mais 
plus important la recherche des voisins qui est le gouleau d'étranglement de la méthode.

Slide 18
========
Voici quelques résultats. 
Tout d'abord une simulation d'un dam break où l'on compare SPH et l'ARPS.
Ici la visualisation de l'état des particules. 
Pour cette simulation on a obtenu une accélération moyenne de 3.8.
On peut constate que l'on a un comportement très proche d'une simulation classique.

Slide 19
========
Et un second exemple dans lequel on a créé un courant permanent.
Une fois que le flux est installé, un grand nombre de particules bougent très peu mais réagissent aux intéractions avec les particules actives.
L'accélération moyenne est de 2.7 et on voit bien dans cet exemple que l'activation/la désactivation des particules est bien gérée par l'algorithme.

Slide 20
========
Passons maintenant à la simulation de vêtement.
Pour des objets structurés comme les vêtements, l'intégration explicite nécessite de très petit pas de temps et ralentit considérablement la simulation.
Une solution classique consiste à utiliser un intégrateur implicite comme celui proposé par Baraff et Witkin.
Les éq. du mouvement sont alors discrétisés en considérant les forces à la fin du pas de temps.
En utilisant un développement de Taylor Young, on arrive à un système linéaire qu'il faut résoudre.
La résolution est cher mais permet d'utiliser un pas de temps beaucoup plus grand.
Notre idée ici est de dériver un intégrateur implicite pour l'ARPS pour réduire la taille du système linéaire en accord avec le nombre de particules actives.

Slide 21
========
On est tout simplement parti des équations du mouvement décrite par l'ARPS.
On a suivi la même procédure que je viens de décrire : discrétisation, développement taylor.
On obtient un système linéaire similaire à celui que l'on avait mais qui contient 2 nouveaux termes.
Une matrice et un vecteur qui servent à encapsuler l'état des particules.
On peut observer que lorsque les particules sont inactives, on retrouve une intégration explicite.
Alors que lorsque les particules sont actives on retrouve l'intégration implicite.
Donc on peut extraire les particules inactives du système linéaire et ainsi réduire sa taille.

Slide 22
========
On a implémenté ce solveur hybride sur un cas extrêmement simple d'un vêtement qui tombe sous l'effet de la gravité.
Dans cet exemple, les particules inactives sont intégrées explicitement, les particules actives sont intégrées implicitement et on a bien une réduction du système linéaire qui permet d'obtenir une accélération de 2.7.

Slide 23
========
Voilà pour cette première partie.
On a étendu à l'informatique graphique une nouvelle approche 
pour approximer de manière cohérente des simulations de particules.
Pour les

On l'a fait de deux manières, via une application aux fluides et via une application aux vêtements.

Dans les deux cas, on a obtenu des accélérations encourageantes.
La méthode n'est pas sans limite, on a observé des instabilités concernant l'intégration implicite, qui viennent de la fonction de restriction utilisée pour gérer la transition des particules.
Ça nécessiterait de mieux comprendre l'origine du problème pour pouvoir apporter des solutions.
Sinon, ça serait également intéressant d'étudier l'utilisation de critère visuel tel que la distance à la caméra pour déterminer l'état des particules et ainsi concentrer les ressouces là où elles contribuent le plus à l'intérêt visuel.
